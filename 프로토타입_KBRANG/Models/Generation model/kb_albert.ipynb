{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KB_BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요한 모델 및 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/KB-AI-Research/KB-ALBERT.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertForSequenceClassification, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizer and Model\n",
    "kb_albert_model_path = \"/content/drive/MyDrive/kb_chs/data/kb-albert-char-base-v2\"  # Update the path here \n",
    "model = AutoModel.from_pretrained(kb_albert_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(kb_albert_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv('/content/drive/MyDrive/kb_chs/data/aihub_ox.csv')\n",
    "\n",
    "# Custom Dataset\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df            # 문제 데이터 파일과 토큰화된 데이터\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context = self.df['context'].iloc[idx] # 질문의 바탕이 되는 내용\n",
    "        question = self.df['question'].iloc[idx] # 질문\n",
    "        answer = self.df['answer'].iloc[idx] # 정답\n",
    "        inputs = self.tokenizer.encode_plus(question, context, max_length=512, padding='max_length', truncation=True, return_tensors='pt', return_token_type_ids=False)\n",
    "        return {'inputs': inputs, 'answer': answer}\n",
    "\n",
    "# Split the dataframe into train and validation data\n",
    "train, test_df = train_test_split(df, test_size=0.2, random_state=42) # 데이터 분리\n",
    "train_df, val_df = train_test_split(train, test_size=0.2, random_state=42) # 데이터 분리\n",
    "\n",
    "# Initialize Datasets and Dataloaders for train and validation set\n",
    "train_dataset = QADataset(train_df, tokenizer) # 훈련 데이터\n",
    "val_dataset = QADataset(val_df, tokenizer) # 검정 데이터\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)  # No need to shuffle validation data\n",
    "\n",
    "# Initialize model\n",
    "model = AlbertForSequenceClassification.from_pretrained(kb_albert_model_path, num_labels=2) # 2개의 라벨 분류\n",
    "model = model.to('cuda') # GPU 사용 설정\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = Adam(model.parameters(), lr=1e-4) # Adam 옵티마이저\n",
    "\n",
    "# 설정값\n",
    "best_loss = 9999999\n",
    "max_patience = 5\n",
    "num_patience = 0\n",
    "\n",
    "# Model Training\n",
    "for epoch in range(50):  # Number of epochs\n",
    "    model.train()\n",
    "    train_loss_list = []\n",
    "    for batch in train_dataloader: # 훈련 데이터 배치 반복\n",
    "        inputs = {k: v.squeeze(1).to('cuda') for k, v in batch['inputs'].items()}  # squeeze the unnecessary dimension\n",
    "        labels = torch.stack([torch.tensor(int(a)).to('cuda') for a in batch['answer']]) # 입력 데이터\n",
    "        \n",
    "        # 모델 순전파\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # 역전파 및 가중치 업데이트\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_list.append(loss.item())\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        val_loss_list = []\n",
    "        y_true = []  # 실제 정답값 저장\n",
    "        y_pred = []  # 예측값 저장\n",
    "        for batch in val_dataloader:\n",
    "            inputs = {k: v.squeeze(1).to('cuda') for k, v in batch['inputs'].items()} # 입력 데이터\n",
    "            labels = torch.stack([torch.tensor(int(a)).to('cuda') for a in batch['answer']]) # 정답값\n",
    "            outputs = model(**inputs, labels=labels) # 예측값\n",
    "            loss = outputs.loss\n",
    "            val_loss_list.append(loss.item())\n",
    "\n",
    "            _, predicted = torch.max(outputs.logits, 1) # 예측값 조정\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item() # 정답률\n",
    "            y_true.extend(labels.cpu().numpy()) # 실제값 저장 \n",
    "            y_pred.extend(predicted.cpu().numpy()) # 예측값 저장\n",
    "\n",
    "    # y_true와 y_pred를 사용하여 f1 스코어 계산\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f'train_loss: {np.mean(train_loss_list):.5f} val_loss: {np.mean(val_loss_list):.5f}') # train과 valid의 loss값\n",
    "    print(f\"val_Accuracy: {(100 * correct / total):.2f} val_F1 Score: {f1:.2f}\") # val 데이터의 정확도와 f1-score\n",
    "\n",
    "    val_loss = np.mean(val_loss_list)\n",
    "    if best_loss > val_loss: # loss 최소화\n",
    "        print(\"Save new model on epoch: %d\" % (epoch + 1))\n",
    "        best_loss = val_loss\n",
    "        best_model = model\n",
    "        print('Model Saved')\n",
    "\n",
    "    else:\n",
    "        num_patience += 1\n",
    "\n",
    "    if num_patience >= max_patience: # Early Stop\n",
    "        print(f\"Early Stopped after epoch {epoch+1}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = QADataset(test_df, tokenizer) # 검정 데이터\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "- kb-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    y_true = []  # 실제 정답값 저장\n",
    "    y_pred = []  # 예측값 저장\n",
    "    for batch in test_dataloader:\n",
    "        inputs = {k: v.squeeze(1).to('cuda') for k, v in batch['inputs'].items()} # 입력 데이터\n",
    "        labels = torch.stack([torch.tensor(int(a)).to('cuda') for a in batch['answer']]) # 정답값\n",
    "        outputs = model(**inputs) # 예측값\n",
    "        _, predicted = torch.max(outputs.logits, 1) # 예측값 조정\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item() # 정답률\n",
    "        y_true.extend(labels.cpu().numpy()) # 실제값 저장\n",
    "        y_pred.extend(predicted.cpu().numpy()) # 예측값 저장\n",
    "\n",
    "\n",
    "# y_true와 y_pred를 사용하여 f1 스코어 계산\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print('Accuracy: %d %%' % (100 * correct / total)) #\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kb_ai",
   "language": "python",
   "name": "kb_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
